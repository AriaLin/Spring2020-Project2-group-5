return (count)
}
## Count personal pronouns in speeches
inaugu.info$Icount<-word.freq('I',inaugu.info)
inaugu.info$youcount<-word.freq('you',inaugu.info)+
word.freq('You',inaugu.info)
inaugu.info$wecount<-word.freq('we',inaugu.info)+
word.freq('We',inaugu.info)
inaugu.info$theycount<-word.freq('they',inaugu.info)
## Compare the number of personal pronouns
library(ggplot2)
library(ggpubr)
p1<-ggplot(inaugu.info)+
geom_violin(aes(x=Party,y=Icount,fill=Party,color=Party),alpha=0.5)+
labs(y='Frequency',title="Mentions of I")+
theme(plot.title = element_text(hjust = 0.5))
p2<-ggplot(inaugu.info)+
geom_violin(aes(x=Party,y=youcount,fill=Party,color=Party),alpha=0.5)+
labs(y='Frequency',title="Mentions of You")+
theme(plot.title = element_text(hjust = 0.5))
p3<-ggplot(inaugu.info)+
geom_violin(aes(x=Party,y=wecount,fill=Party,color=Party),alpha=0.5)+
labs(y='Frequency',title="Mentions of We")+
theme(plot.title = element_text(hjust = 0.5))
p4<-ggplot(inaugu.info)+
geom_violin(aes(x=Party,y=theycount,fill=Party,color=Party),alpha=0.5)+
labs(y='Frequency',title="Mentions of They")+
theme(plot.title = element_text(hjust = 0.5))
ggarrange(p1,p2,p3,p4,common.legend=TRUE,legend = 'right')
if(!require("pacman"))
install.packages("pacman")
pacman::p_load_gh(c(
'trinker/lexicon',
'trinker/textclean',
'trinker/textshape',
'trinker/syllable',
'trinker/readability'
))
library(readability)
readscore<-function(row){
grade<-readability(row[7],grouping.var = NULL)
return (grade)
}
inaugu.info<-adply(inaugu.info,1,readscore)
inaugu.info<-inaugu.info[,-12]
## Prepare for heatmap
id_name<-paste(inaugu.info$File,'-',inaugu.info$Term,sep='')
id_name<-c(id_name,c('DemocraticEND','','RepublicanBEGIN'))
party<-c(inaugu.info$Party,rep('Democratic',3))
id_name<-id_name[order(party)]
grade<-inaugu.info[,12:17]
grade[47:49,]<-rep(NA,6)
colnames(grade)<-c('F-K','G-F','C-L','SMOG','A-R','Average')
heat_mat<-cbind(grade,party)
heat_mat<-heat_mat[order(party),]
rownames(heat_mat)<-id_name
#devtools::install_github('ramnathv/htmlwidgets')
#library(htmlwidgets)
#install.packages('d3heatmap')
library(d3heatmap)
library(shiny)
div(d3heatmap(heat_mat[,-7], scale="none", colors= "Greens",
xaxis_font_size = 8,Rowv = FALSE,Colv=FALSE,show_grid=TRUE),
align='center')
library(tm)
library(tidytext)
### The democratic Party
setwd('~/Documents/GitHub/Spring2018-Project1-Hongyu-Li')
##Write the democratic speeches into the democreatic file
for(i in 1:nrow(inaugu.info)){
if (inaugu.info[i,4]=='Democratic'){
text <- inaugu.info$Fulltext[i]
filename <- paste0(inaugu.info$File[i], "-",
inaugu.info$Term[i], ".txt")
sink(file = filename) %>% # open file to write
cat(text)  # write the file
sink() # close the file
}
}
speech.democratic<-Corpus(DirSource('~/Documents/GitHub/Spring2018-Project1-Hongyu-Li'))
#Clean the data
speech.democratic<-tm_map(speech.democratic, stripWhitespace)
speech.democratic<-tm_map(speech.democratic, content_transformer(tolower))
speech.democratic<-tm_map(speech.democratic, removeWords, stopwords("english"))
speech.democratic<-tm_map(speech.democratic, removeWords, character(0))
speech.democratic<-tm_map(speech.democratic, removePunctuation)
d.tdm<-TermDocumentMatrix(speech.democratic)
d.tdm.tidy<-tidy(d.tdm)
d.tdm.tidy<-d.tdm.tidy %>% filter(count>=3)
democratic<-summarise(group_by(d.tdm.tidy, term), sum(count))
Sys.setenv(JAVA_HOME='～/Library/Java/JavaVirtualMachines/jdk-13.0.2.jdk/Contents/Home')
library(rJava)
library(rJava)
install.packages("rjava")
install.packages("installr")
library(installr)
updateR()
install.packages("installr")
library(installr)
install.packages('devtools') #assuming it is not already installed
library(devtools)
install_github('andreacirilloac/updateR')
library(updateR)
updateR(admin_password = 'Admin user password')
install.packages(as.vector(needed_packages))
knitr::opts_chunk$set(echo = TRUE)
Sys.setenv(JAVA_HOME='～/Library/Java/JavaVirtualMachines/jdk-13.0.2.jdk/Contents/Home')
library(rJava)
library(wordcloud2)
library(htmlwidgets)
knitr::opts_chunk$set(echo = TRUE)
packages.used=c("dplyr","textdata","ggplot2","gridExtra","tidytext","wordcloud2","knitr","kableExtra","formattable","stringr","tm","igraph","tidyverse","ggraph","rsconnect","DT","wordcloud","scales","cowplot","reshape2","data.table","lexicon","ggthemes","syuzhet","sentimentr","tibble","qdap")
# 1. check required packages
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# 2.install lacked packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE)
}
# 3.load all packages
library(dplyr) #data manipulation
library(textdata)
library(ggplot2) #visualizations
library(gridExtra) #viewing multiple plots together
library(tidytext) #text mining
library(wordcloud2) #creative visualizations
library(knitr) # for dynamic reporting
library(kableExtra) # create a nicely formated HTML table
library(formattable) # for the color_tile function
library(stringr)
library(tm)
library(igraph)
library(tidyverse)
library(ggraph)
library(rsconnect)
library(DT)
library(wordcloud)
library(scales)
library(cowplot)
library(reshape2)
library(data.table)
library(lexicon)
library(ggthemes)
library(syuzhet)
library(sentimentr)
library(tibble)
library(qdap)
#loading processed lyrics data
load('../output/processed_lyrics.RData')
artists = read_csv('../data/artists.csv')
names(artists) = c("artist", "intro", "formed", "members", "origin")
All_data = dt_lyrics %>%
left_join(artists, by = "artist")
### all images corresponding to digit "3"
zip.3 <- read.table("zip3.txt", header=FALSE, sep=",")
zip.3 <- as.matrix(zip.3)
### all images corresponding to digit "5"
zip.5 <- read.table("zip5.txt", header=FALSE, sep=",")
zip.5 <- as.matrix(zip.5)
### n.3 and n.5 are the total number of "3"s and "5"s, respectively.
n.3 <- length(zip.3[,1])
n.5 <- length(zip.5[,1])
### combine two data sets together
X.full.zip <-rbind(zip.3,zip.5)
dim(X.full.zip)
### define response (labels)
Y.full.zip <- c(rep("Three",n.3),rep("Five",n.5))
length(Y.full.zip)
output.image<-function(vector) {
digit<-matrix(vector, nrow=16, ncol=16)
#index= seq(from=1, to =16, by=1)
index= seq(from=16, to =1, by=-1)
sym_digit = digit[,index]
image(sym_digit, col= gray((8:0)/8), axes=FALSE)
}
par(mfrow=c(5,5),mai=c(0.1,0.1,0.1,0.1))
for(i in 1:25) {
output.image(zip.3[i,])
}
x.test=training_set_X,
x.test=training_set_X
training_set_X<-X.full.zip[-test_index,]
### all images corresponding to digit "3"
zip.3 <- read.table("zip3.txt", header=FALSE, sep=",")
zip.3 <- as.matrix(zip.3)
### all images corresponding to digit "5"
zip.5 <- read.table("zip5.txt", header=FALSE, sep=",")
zip.5 <- as.matrix(zip.5)
### n.3 and n.5 are the total number of "3"s and "5"s, respectively.
n.3 <- length(zip.3[,1])
n.5 <- length(zip.5[,1])
### combine two data sets together
X.full.zip <-rbind(zip.3,zip.5)
dim(X.full.zip)
### define response (labels)
Y.full.zip <- c(rep("Three",n.3),rep("Five",n.5))
length(Y.full.zip)
output.image<-function(vector) {
digit<-matrix(vector, nrow=16, ncol=16)
#index= seq(from=1, to =16, by=1)
index= seq(from=16, to =1, by=-1)
sym_digit = digit[,index]
image(sym_digit, col= gray((8:0)/8), axes=FALSE)
}
par(mfrow=c(5,5),mai=c(0.1,0.1,0.1,0.1))
?par
for(i in 1:25) {
output.image(zip.3[i,])
}
par(mfrow=c(5,5),mai=c(0.1,0.1,0.1,0.1))
for(i in 1:25) {
output.image(zip.5[i,])
}
## Solution goes here ---------
set.seed(1)
n<-nrow(X.full.zip)
n.test<-ceiling(0.2*n)
test_index<-sample(1:n,n.test,replace=F)
training_set_X<-X.full.zip[-test_index,]
test_set_X<-X.full.zip[test_index,]
training_set_Y<-Y.full.zip[-test_index]
test_set_Y<-Y.full.zip[test_index]
# Create basic training data from iris
X.example <- as.matrix(iris[51:150,1:2])
Y.example <- as.character(iris[51:150,5])
head(X.example,3)
head(Y.example,3)
# kNN function
KNN.decision <- function(x.test,
X.data,
Y.data,
K = 5) {
#n <- nrow(X.data)
dists.vec <- sqrt((x.test[1]- X.data[,1])^2 + (x.test[2]-X.data[,2])^2)
neighbors  <- order(dists.vec)[1:K]
neighb.dir <-  Y.data[neighbors]
choice     <- names(which.max(table(neighb.dir)))
return(choice)
}
# Evaluate kNN.decision() at x.test.1:
x.test.1 <- c(5.5,3.0)
p1.choice <- KNN.decision(x.test=x.test.1,
X.data=X.example,
Y.data=Y.example,
K=5)
p1.choice
# Evaluate kNN.decision() at x.test.2:
x.test.2 <- c(7.5,3)
p2.choice <- KNN.decision(x.test=x.test.2,
X.data=X.example,
Y.data=Y.example,
K=5)
p2.choice
# Plot X2 versus X1 with the test points
plot(X.example[,1],
X.example[,2],
xlab="X1",
ylab="X2",
col=factor(Y.example))
col1 <- ifelse(p1.choice=="versicolor",1,2)
points(x.test.1[1],x.test.1[2],pch="*",cex=3,col=col1)
text(x.test.1[1],x.test.1[2]+.1,labels=p1.choice,cex=.6,col=col1)
col2 <- ifelse(p2.choice=="versicolor",1,2)
points(x.test.2[1],x.test.2[2],pch="*",cex=3,col=col2)
text(x.test.2[1],x.test.2[2]+.1,labels=p2.choice,cex=.6,col=col2)
legend("topleft",legend=levels(factor(Y.example)),
fill=1:2,cex=.75)
x.test=training_set_X
X.data=training_set_X
Y.data=training_set_Y
K = 5
n <- nrow(x.test)
m <- nrow(X.data)
choice<-c()
dists.vec<-c()
for(i in 1:n){
for(j in 1:m){
dists.vec[j] <-sqrt((X.data[j]-x.test[i,])^2)
}
neighbors  <- order(dists.vec)[1:K]
neighb.dir <-  Y.data[neighbors]
choice[i]  <- names(which.max(table(neighb.dir)))
}
shiny::runApp('Documents/GitHub/fall2019-proj2--sec2-grp3/app')
install.packages("anytime")
install.packages("anytime")
knitr::opts_chunk$set(echo = TRUE)
#import raw data
data <- read.csv("../data/Housing_Litigations.csv", header = T)
#change date format
library(anytime)
data$CaseOpenDate<- anydate(data$CaseOpenDate)
#clean casestatus
ca <- strsplit(sapply(data$CaseStatus, as.character), split=" ")
ca <- lapply(ca, "[[", 1)
data$CaseStatus <- unlist(ca)
data$CaseStatus[data$CaseStatus == "Exempt-"] <- "Exempt"
data$CaseStatus[data$CaseStatus == "WithDrawn/Abandoned-"] <- "WithDrawn/Abandoned"
data$CaseStatus[data$CaseStatus == "Rescinded-"] <- "Rescinded"
data$CaseStatus[data$CaseStatus == "Rejected-"] <- "Rejected"
View(ca)
View(data)
#transfer na to 0 for penalty
data$Penalty[is.na(data$Penalty)] <- 0
#export data
data <- na.omit(data)
save(data, file="../output/processed_data.Rdata")
building <- data %>% group_by(BuildingID) %>% tally()
geo <- data %>% dplyr::select(BuildingID, Latitude, Longitude, StreetName, HouseNumber, Respondent)
building_geo <- left_join(lit_building, lit_geo, by = "BuildingID")
library(rgdal)
library(leaflet)
library(shiny)
library(dplyr)
library(raster)
library(tigris)
library(sp)
library(ggmap)
library(maptools)
library(broom)
library(httr)
data1<-read.csv("../data/processed_data.csv")
under <- readOGR("../data/ZIP_CODE_040114.shp")
ui <- fluidPage(
h1("Map of Frequences"),
sidebarLayout(
sidebarPanel(
selectInput("Zip_frequence", "Case:",
c("Comprehensive" = "Comprehensive",
"Heat and Hot Water" = "Heat and Hot Water",
"Access Warrant - Non-Lead" = "Access Warrant - Non-Lead",
"Tenant Action" = "Tenant Action",
"False Certification Non-Lead" = "False Certification Non-Lead",
"Heat Supplemental Cases" = "Heat Supplemental Cases",
"Tenant Action/Harrassment" = "Tenant Action/Harrassment",
"CONH" = "CONH",
"Access Warrant - lead" = "Access Warrant - lead",
"Comp Supplemental Cases" = "Comp Supplemental Cases",
"Lead False Certification" = "Lead False Certification",
"Failure to Register Only" = "Failure to Register Only",
"7A" = "7A",
"HLD - Other Case Type" = "HLD - Other Case Type"),
selected = "Comprehensive",
multiple = TRUE),
checkboxGroupInput("CaseOpenDate", "Case Open Date:",
c("2000" = "2000",
"2001" = "2001",
"2002" = "2002",
"2003" = "2003",
"2004" = "2004",
"2005" = "2005",
"2006" = "2006",
"2007" = "2007",
"2008" = "2008",
"2009" = "2009",
"2010" = "2010",
"2011" = "2011",
"2012" = "2012",
"2013" = "2013",
"2014" = "2014",
"2015" = "2015",
"2016" = "2016",
"2017" = "2017",
"2018" = "2018"), selected = "2018")
),
mainPanel(
leafletOutput("mymap1",height = 1000)
)
)
)
server=function(input, output) {
output$mymap1 <- renderLeaflet({
data1$CaseOpenDate <- as.Date(data1$CaseOpenDate) %>% format("%Y")
datasliced<-dplyr::filter(data1, data1$CaseType==input$Zip_frequence, data1$CaseOpenDate==input$CaseOpenDate)
#data1[data1$CaseType==input$Zip_frequence,]
ZIPCODE<-names(table(datasliced$Zip))
frequence<-unname(table(datasliced$Zip))
Zip<-as.data.frame(cbind(ZIPCODE,frequence))
under1 <- subset(under, is.element(Zip$ZIPCODE, under$ZIPCODE))
under2 <- subset(under1, is.element(under1$ZIPCODE, Zip$ZIPCODE))
under2@data = merge(x=under2@data, y=Zip, by = "ZIPCODE", all.x = TRUE)
subdat1 <- spTransform(under2, CRS("+init=epsg:4326"))
subdat1@data$frequence <- as.numeric(subdat1@data$frequence)
subdat1$lab <- paste("<p>", "ZIPCODE", subdat1$ZIPCODE, "<p>",
"<p>", "Case Frequence", subdat1$frequence, "<p>")
pal <- colorNumeric(
palette = "Blues",
domain = subdat1$frequence
)
m <- leaflet(under) %>%
addProviderTiles(providers$Stamen.Toner) %>%
setView(lng = -73.98928, lat = 40.75042, zoom = 12)%>%
addPolygons(data = subdat1,
weight = 1,
smoothFactor = 0.5,
color = "white",
fillOpacity = 0.8,
fillColor = pal(subdat1$frequence),
label = lapply(subdat1$lab, HTML),
highlight = highlightOptions(weight = 10,
color = "White",
bringToFront = TRUE))})
}
# Run the app ----
shinyApp(ui = ui, server = server)
runApp('Documents/GitHub/Spring2020-Project2-group-5/app')
runApp('Documents/GitHub/Spring2020-Project2-group-5/app')
(
div
(id = 'canvas',
navbarPage
(strong("Homeless needs help?",style="color: white;"),
theme=shinytheme("cerulean"),
tabPanel('Map',
div(class="outer",
leafletOutput("map",width="100%",height=700),
absolutePanel(id = "control", class = "panel panel-default", fixed = TRUE, draggable = TRUE,
top = 170, left = 20, right = "auto", bottom = "auto", width = 250, height = "auto",
checkboxGroupInput("enable_markers", "Homeless Resources:",
choices = c("condom_distribution","Homebase_Centers","Job_Centers","Food_Stamp_Centers","after_school_programs","Health_Insurance"),
selected = c("condom_distribution","Homebase_Centers","Job_Centers","Food_Stamp_Centers","after_school_programs","Health_Insurance"))
regionNames(mapName)
)
)
)
)
)
)
regionNames(mapName)
regionNames(mapName)
regionNames(mapName)
library(tidyverse)
library(leaflet)
library(shiny)
library(plotly)
library(rgdal)
library(raster)
library(tigris)
library(sp)
library(ggmap)
library(maptools)
library(broom)
library(httr)
regionNames(mapName)
regionNames(mapName)
runApp('Documents/GitHub/fall2019-proj2--sec2-grp3/app')
load('processed_data.Rdata')
runApp('Documents/GitHub/fall2019-proj2--sec2-grp3/app')
runApp()
runApp()
runApp('Documents/GitHub/fall2019-proj2--sec2-grp3/app')
install.packages("janitor")
runApp('Documents/GitHub/fall2019-proj2--sec1-grp7/app')
runApp('Documents/GitHub/fall2019-proj2--sec1-grp7/app')
runApp('Documents/GitHub/fall2019-proj2--sec2-grp4/tree_app')
my<-read.csv("../data/homeless/New_York_City_Population_By_Community_Districts.csv")
setwd("~/Documents/GitHub/Spring2020-Project2-group-5")
my<-read.csv("../data/homeless/New_York_City_Population_By_Community_Districts.csv")
my<-read.csv("../Spring2020-Project2-group-5/data/homeless/New_York_City_Population_By_Community_Districts.csv")
View(my)
map_data <- geo_join(nhyc_cd_data, my, "borough_cd_id",  "borough_cd_id", how = "inner")
library(shiny)
library(leaflet)
library(data.table)
library(plotly)
library(shinyWidgets)
library(googleVis)
library(geosphere)
library(leaflet.extras)
library(ggmap)
library(tidyverse)
#remotes::install_github("mfherman/nycgeo")
library(nycgeo)
library(sf)
library(shinythemes)
library(leaflet)
library(lubridate)
library(scales)
library(tigris)
map_data <- geo_join(nhyc_cd_data, my, "borough_cd_id",  "borough_cd_id", how = "inner")
nhyc_cd_data <- cd_sf
map_data <- geo_join(nhyc_cd_data, my, "borough_cd_id",  "borough_cd_id", how = "inner")
my <- my%>%
mutate(borough_cd_id = as.character(borough_cd_id), as.character = as.numeric(borough_id))
map_data <- geo_join(nhyc_cd_data, my, "borough_cd_id",  "borough_cd_id", how = "inner")
runApp('app')
knitr::opts_chunk$set(echo = TRUE)
# load homeless data
Homebase_Centers<-read.csv('../data/homeless/Directory_Of_Homebase_Locations.csv')
after_school_programs<-read.csv('../data/homeless/DYCD_after-school_programs__Runaway_And_Homeless_Youth.csv')
Health_Insurance<-read.csv('../data/homeless/Primary_Care_Access_and_Planning_-_Health_Insurance_Enrollment.csv')
Job_Centers<-read.csv('../data/homeless/Directory_Of_Job_Centers.csv')
condom_distribution<-read.csv('../data/homeless/NYC_Condom_Availability_Program_-_HIV_condom_distribution_locations.csv')
Food_Stamp_Centers<-read.csv('../data/homeless/Directory_of_Food_Stamp_Centers.csv')
radar <- read.csv('../data/homeless/radar.csv')
save(Homebase_Centers,Food_Stamp_Centers,after_school_programs,Health_Insurance,Job_Centers,condom_distribution, file="../app/homeless.RData")
runApp('app')
runApp()
runApp('app')
my<-read.csv("../data/homeless/New_York_City_Population_By_Community_Districts.csv")
View(map_data)
View(map_data)
View(map_data)
runApp('app')
runApp('~/Documents/GitHub/fall2019-proj2--sec1-grp7/app')
runApp('app')
runApp('app')
runApp('app')
runApp('app')
runApp('app')
runApp('app')
